import requests
import base64

class GitHubSearch:
    def __init__(self, token=None):
        #self.headers = {'Accept': 'application/vnd.github.v3+json'}
        #if token:
        #    self.headers['Authorization'] = f'token {token}'
        self.base_url = 'https://api.github.com/search/repositories'

    def get_readme_content(self, full_name):
        """
        è·å–æŒ‡å®š GitHub ä»“åº“çš„ README.md æ–‡ä»¶å†…å®¹ã€‚

        å‚æ•°:
        - full_name (str): owner(ç”¨æˆ·åæˆ–ç»„ç»‡å)/repo(ä»“åº“åç§°)

        è¿”å›:
        - str: README.md æ–‡ä»¶çš„å†…å®¹ï¼Œå¦‚æœæ˜¯äºŒè¿›åˆ¶æ–‡ä»¶åˆ™è¿”å›è§£ç åçš„å­—ç¬¦ä¸²ã€‚
        """
        url = f"https://api.github.com/repos/{full_name}/readme"
        response = requests.get(url)
        try:
            if response.status_code != 200:
                raise Exception(f"Error fetching data: {response.status_code}, {response.text}")

            content_info = response.json()
            # README çš„å†…å®¹æ˜¯ä»¥ base64 ç¼–ç çš„
            encoded_content = content_info['content']
            # è§£ç å¾—åˆ°åŸå§‹çš„æ–‡æœ¬å†…å®¹
            decoded_content = base64.b64decode(encoded_content).decode('utf-8')

            return decoded_content
        except Exception as e:
            # è¿™é‡Œå¯ä»¥è®°å½•é”™è¯¯ä¿¡æ¯ï¼Œæˆ–è€…é‡‡å–å…¶ä»–æªæ–½
            print(f"An error occurred: {e}")
            return None
    # å¦‚æœ html_url éœ€è¦ä½œä¸ºå¯ç‚¹å‡»çš„é“¾æ¥å±•ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥å…ˆå°†å…¶è½¬æ¢ä¸º HTML æ ¼å¼
    def make_clickable(self, val):
        return f'<a href="{val}" target="_blank">{val}</a>'

    def search_repositories(self, query, language=None, min_stars=0, sort='best_match', order='desc', created=None, pushed=None, per_page=10):
        """
        ä½¿ç”¨ GitHub Search API æœç´¢ä»“åº“ã€‚

        å‚æ•°:
        - query (str): æœç´¢å…³é”®è¯ã€‚
        - language (str, optional): ä»“åº“ç¼–ç¨‹è¯­è¨€ã€‚
        - sort (str, optional): æ’åºæ–¹å¼ï¼ˆ'stars', 'forks', 'updated'ï¼‰ã€‚
        - order (str, optional): æ’åºé¡ºåºï¼ˆ'asc', 'desc'ï¼‰ã€‚
        - created (str, optional): åˆ›å»ºæ—¶é—´èŒƒå›´ï¼ˆä¾‹å¦‚ '>=2024-01-01'ï¼‰ã€‚
        - pushed (str, optional): æœ€è¿‘æ›´æ–°æ—¶é—´èŒƒå›´ï¼ˆä¾‹å¦‚ '>=2024-01-01'ï¼‰ã€‚
        - per_page (int, optional): æ¯é¡µæ˜¾ç¤ºçš„ç»“æœæ•°é‡ã€‚

        è¿”å›:
        - dict: è§£æåçš„æœç´¢ç»“æœã€‚
        """
        # æ„å»ºæœç´¢ URL
        url = self.base_url
        params = {'q': query}

        if language:
            params['q'] += f'+language:{language}'

        if min_stars > 0:
            query += f"+stars:>={min_stars}"

        if sort != 'best_match':
            params['sort'] = sort

        if order:
            params['order'] = order

        if created:
            params['q'] += f'+created:{created}'

        #if pushed:
        #    params['q'] += f'+pushed:{pushed}'

        if per_page:
            params['per_page'] = per_page

        # å‘é€è¯·æ±‚
        print(f"url: {url}, params:{params}")

        response = requests.get(url, params=params)
        #print(f"response: {response}")
        # æ£€æŸ¥å“åº”çŠ¶æ€ç 
        if response.status_code != 200:
            raise Exception(f"Error fetching data: {response.status_code}")

        # è§£æ JSON å“åº”
        results = response.json()
        #print(f"results: {results}")

        # è§£æå¹¶è¿”å›ç»“æœ
        parsed_results = {
            'total_count': results['total_count'],
            'items': [
                {
                    'â­': item['stargazers_count'],
                    'åç§°': item['name'],
                    'è¯­è¨€': item['language'],
                    #'full_name': item['full_name'],
                    #'html_url': self.make_clickable(item['html_url']),
                    'é“¾æ¥': item['html_url'],
                    'æè¿°': item['description'],
                    #'open_issues_count': item['open_issues_count'],
                    'æ›´æ–°æ—¶é—´ğŸ•’': item['created_at'],
                    'Forkæ•°': item['forks_count'],
                    #'updated_at': item['updated_at'],
                    'ReadMe': self.get_readme_content(item['full_name']),
                }
                for item in results['items']
            ]
        }


        return parsed_results



# ç¤ºä¾‹è°ƒç”¨
if __name__ == '__main__':
    gh_search = GitHubSearch()  # å¦‚æœéœ€è¦è®¤è¯ï¼Œè¯·æä¾›æ‚¨çš„ä¸ªäººè®¿é—®ä»¤ç‰Œ
    try:

        #repos = gh_search.search_repositories(query="agentless", sort="stars", order="desc")
        #print(repos)
        repos = gh_search.search_repositories(
            query='Agentless',
            #language='Python',
            #sort='updated',
            order='desc',
            #per_page=100
        )

        for repo in repos['items']:
            print(f"Repo Name: {repo['name']}, Stars: {repo['stargazers_count']}, Language: {repo['language']} ...")
            #print(f"""readme: {get_readme_content(repo['full_name'])}""")
            #readme_content = gh_search.get_readme_content(full_name="OpenAutoCoder/Agentless")
            #print(readme_content)


    except Exception as e:
        print(e)